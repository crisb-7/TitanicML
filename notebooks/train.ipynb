{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Class1</th>\n",
       "      <th>Class2</th>\n",
       "      <th>Class3</th>\n",
       "      <th>...</th>\n",
       "      <th>Alone</th>\n",
       "      <th>FamSize</th>\n",
       "      <th>SameTickets</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_U</th>\n",
       "      <th>Master</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.338125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685892</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.43225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639463</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex      Age  SibSp  Parch      Fare  Class1  \\\n",
       "0            1         0    0  0.26975      1      0  0.338125       0   \n",
       "1            2         1    1  0.46975      1      0  0.685892       1   \n",
       "2            3         1    1  0.31975      0      0  0.350727       0   \n",
       "3            4         1    1  0.43225      1      0  0.639463       1   \n",
       "4            5         0    0  0.43225      0      0  0.352955       0   \n",
       "\n",
       "   Class2  Class3  ...  Alone  FamSize  SameTickets  Deck_A  Deck_B  Deck_C  \\\n",
       "0       0       1  ...      0        1            1       0       0       0   \n",
       "1       0       0  ...      0        1            1       0       0       1   \n",
       "2       0       1  ...      1        0            1       0       0       0   \n",
       "3       0       0  ...      0        1            2       0       0       1   \n",
       "4       0       1  ...      1        0            1       0       0       0   \n",
       "\n",
       "   Deck_D  Deck_E  Deck_U  Master  \n",
       "0       0       0       1       0  \n",
       "1       0       0       0       0  \n",
       "2       0       0       1       0  \n",
       "3       0       0       0       0  \n",
       "4       0       0       1       0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../datasets/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "\n",
    "Since the data is already split for us, there is no need to use a data-splitting function from a library (or even do it ourselves manually, hehe). Instead, we're going to create a partition of our *df* dataset as training data, and load the test dataset to have them both ready for our Machine Learning Model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass this data frame through our data pipeline so we have homogeneous datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=[\"PassengerId\", \"Survived\"])\n",
    "y_train = train.Survived"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "param_grid = {\n",
    "    # \"loss\": [\"log_loss\", \"deviance\", \"exponential\"],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.5],\n",
    "    \"n_estimators\": [25, 50, 100, 500, 1000, 2000],\n",
    "    \"subsample\": [0.1, 0.25, 0.5, 0.75, 1],\n",
    "    \"criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"min_samples_split\": [2, 3, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 3], \n",
    "    \"max_depth\": [1, 2, 3, 4, 5],\n",
    "    \"min_impurity_decrease\": [0.001, 0.01, 0.025, 0.05],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "n_folds = 10\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100, cv=n_folds)\n",
    "search_results = random_search.fit(x_train, y_train)\n",
    "\n",
    "best_model = search_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.344991</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.837278</td>\n",
       "      <td>0.032564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.755456</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>log2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.837266</td>\n",
       "      <td>0.034147</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.993931</td>\n",
       "      <td>0.076309</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.836155</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "58       0.344991      0.011990         0.002705        0.000644   \n",
       "15       0.755456      0.008270         0.003902        0.000295   \n",
       "29       0.993931      0.076309         0.003394        0.000795   \n",
       "\n",
       "   param_subsample param_n_estimators param_min_samples_split  \\\n",
       "58               1                500                       5   \n",
       "15            0.75               1000                       2   \n",
       "29               1               2000                       5   \n",
       "\n",
       "   param_min_samples_leaf param_min_impurity_decrease param_max_features  ...  \\\n",
       "58                      1                       0.025               sqrt  ...   \n",
       "15                      3                       0.001               log2  ...   \n",
       "29                      2                        0.05               sqrt  ...   \n",
       "\n",
       "   split3_test_score split4_test_score split5_test_score  split6_test_score  \\\n",
       "58          0.876404          0.865169          0.831461           0.831461   \n",
       "15          0.865169          0.876404          0.842697           0.842697   \n",
       "29          0.876404          0.865169          0.853933           0.820225   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "58           0.797753           0.887640           0.842697         0.837278   \n",
       "15           0.820225           0.876404           0.842697         0.837266   \n",
       "29           0.820225           0.887640           0.831461         0.836155   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "58        0.032564                1  \n",
       "15        0.034147                2  \n",
       "29        0.038911                3  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search_results.cv_results_).sort_values(\"rank_test_score\").drop(columns=\"params\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Importance\n",
      "0           Sex    0.467545\n",
      "4          Fare    0.081315\n",
      "7        Class3    0.075819\n",
      "1           Age    0.053385\n",
      "13  SameTickets    0.051068\n",
      "19       Deck_U    0.049969\n",
      "12      FamSize    0.044974\n",
      "20       Master    0.040994\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({\"Feature\":x_train.columns.to_list(), \"Importance\":best_model.feature_importances_})\n",
    "print(feature_importance.sort_values(by=\"Importance\", ascending=False)[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datapoint per fold: 89\n",
      "Train score:  0.8575\n"
     ]
    }
   ],
   "source": [
    "dpf = round(len(x_train)/n_folds)\n",
    "print(\"Datapoint per fold:\", dpf)\n",
    "\n",
    "print(\"Train score: \", round(best_model.score(x_train, y_train), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.01,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.025,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': 0,\n",
       " 'subsample': 1,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/gradient_boosting_cv10.sav']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'gradient_boosting_cv10.sav'\n",
    "# joblib.dump(best_model, \"../models/\" + filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
